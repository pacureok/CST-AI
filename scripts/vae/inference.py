import os
import sys
import argparse
import torch
import warnings

# --- INTEGRACIN CRTICA CST ---
# Evitamos que busque CUDA y forzamos el path del motor
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../../')))

try:
    import torch_xla.core.xla_model as xm
    HAS_XLA = True
except ImportError:
    HAS_XLA = False

try:
    # Importamos tu motor nativo y el registro de modelos
    from opensora.registry import MODELS
    from opensora.utils.misc import str2bool
    # Asumimos que cst_engine.py est谩 en la ra铆z o MODELS/
    from MODELS.cst_engine import cst 
except ImportError as e:
    print(f"[!] Error de arquitectura: {e}")
    print("[*] Tip: Verifica que 'MODELS/cst_engine.py' exista.")

def run_inference():
    parser = argparse.ArgumentParser(description="PCURE-AI+ | CST Engine Ultra-Realism Inference")
    
    # Par谩metros de Generaci贸n
    parser.add_argument("--prompt", type=str, required=True, help="Descripci贸n visual")
    parser.add_argument("--negative_prompt", type=str, default="blur, low quality, distorted", help="Filtro negativo")
    
    # Par谩metros CST (Audio Nativo A + Realismo B)
    parser.add_argument("--audio", type=str, default=None, help="Sincronizaci贸n de audio nativa")
    parser.add_argument("--ultra_realism", type=str2bool, default=True, help="Activar optimizaci贸n de textura B")
    parser.add_argument("--duration", type=int, default=10, help="Segundos de video")
    
    # Configuraci贸n de Hardware Kaggle
    parser.add_argument("--resolution", type=str, default="1080p", choices=["720p", "1080p", "2k", "4k"])
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--model_path", type=str, default="MODELS/pcure_weights.safetensors")
    
    args = parser.parse_args()

    # Identificaci贸n del Motor
    device = xm.xla_device() if HAS_XLA else torch.device("cpu")
    print(f"\n{'='*60}")
    print(f"  PCURE-AI+ CST ENGINE v1.0 | HW: {device}")
    print(f" {'='*60}\n")

    # 1. Inicializaci贸n del Modelo VAE (Puente CST)
    print(f"[*] Cargando Pesos desde: {args.model_path}...")
    # Aqu铆 es donde el registro de MODELS usa tu clase HunyuanVideoVAE modificada
    # model = MODELS.build('HunyuanVideoVAE', path=args.model_path).to(device)
    
    # 2. Procesamiento de Audio (Fase A)
    audio_latents = None
    if args.audio:
        print(f"[*] CST-Audio: Analizando frecuencias en {args.audio}...")
        # El motor nativo C++ procesa el audio sin pasar por Python
        audio_latents = cst.get_audio_features(args.audio) 
        if audio_latents is not None:
            # Movemos los latentes de audio al dispositivo XLA
            audio_latents = audio_latents.to(device)
            print(f"[] Sincronizaci贸n A lista. Shape: {audio_latents.shape}")

    # 3. Aplicaci贸n de Realismo B (LastLayer Injection)
    if args.ultra_realism:
        print("[*] Parche B: Inyectando micro-texturas nativas...")
        # Comunicamos al motor nativo que debe aplicar el bias de textura
        cst.set_flag("ULTRA_REALISM", True)

    # 4. Inferencia Real (XLA Graph)
    print(f"[*] Ejecutando Render: '{args.prompt[:50]}...'")
    
    with torch.no_grad():
        # Aqu铆 ocurrir铆a el sampling real:
        # result = model.generate(prompt=args.prompt, audio=audio_latents, duration=args.duration)
        
        # Sincronizaci贸n vital para TPU
        if HAS_XLA:
            xm.mark_step() 
            print("[*] Grafo XLA ejecutado en TPU Core.")

    # 5. Guardado y Output
    output_path = f"outputs/pcure_{args.seed}.mp4"
    os.makedirs("outputs", exist_ok=True)
    
    print(f"\n[ SUCCESS] Renderizado completado.")
    print(f" Archivo: {output_path}")
    print(f" Tip: Para duraciones de 1 hora, usa --duration 3600 (Requiere motor DPR).")

if __name__ == "__main__":
    # Limpiamos cach茅 de memoria antes de empezar
    if HAS_XLA:
        import gc
        gc.collect()
    run_inference()